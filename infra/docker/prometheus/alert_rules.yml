groups:
  - name: logops.alerts
    interval: 15s
    rules:
      # 1) Gateway nie odpowiada / scrape przestał działać
      - alert: LogOpsGatewayDown
        expr: up{job="logops-gateway"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Gateway is down"
          description: "Target up{job='logops-gateway'} == 0 przez ≥1m."

      # 2) Brak ingestu w ogóle (twarde zero)
      - alert: LogOpsNoIngest5m
        expr: increase(logops_accepted_total[5m]) <= 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "No logs ingested for 5 minutes"
          description: "Brak przyrostu logops_accepted_total w oknie 5m przez ≥2m."

      # 3) Niski ingest
      - alert: LogOpsLowIngest
        expr: rate(logops_accepted_total[5m]) < 0.2
        for: 5m
        labels:
          severity: info
        annotations:
          summary: "Low ingest rate"
          description: "Średnia szybkość ingestu < 0.2 loga/s przez ≥5m."

      # 4) Burst ingestu
      - alert: LogOpsHighIngestBurst
        expr: rate(logops_accepted_total[1m]) > 20
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "High ingest burst"
          description: "Szybkość ingestu > 20 logów/s przez ≥1m (sprawdź źródła)."

      # 5) Missing TS (WARNING)
      - alert: LogOpsHighMissingTS
        expr: increase(logops_accepted_total[5m]) >= 100
          and ( increase(logops_missing_ts_total[5m])
                / clamp_min(increase(logops_accepted_total[5m]), 1) ) > 0.20
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High share of missing timestamps"
          description: "Udział braków TS > 20% przy ≥100 logach w 5m."

      # 6) Missing TS (CRITICAL)
      - alert: LogOpsVeryHighMissingTS
        expr: increase(logops_accepted_total[5m]) >= 200
          and ( increase(logops_missing_ts_total[5m])
                / clamp_min(increase(logops_accepted_total[5m]), 1) ) > 0.50
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Very high share of missing timestamps"
          description: "Udział braków TS > 50% przy ≥200 logach w 5m."

      # 7) Missing level (WARNING)
      - alert: LogOpsHighMissingLevel
        expr: increase(logops_accepted_total[5m]) >= 100
          and ( increase(logops_missing_level_total[5m])
                / clamp_min(increase(logops_accepted_total[5m]), 1) ) > 0.20
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High share of missing levels"
          description: "Udział braków level > 20% przy ≥100 logach w 5m."

      # 8) Missing level (CRITICAL)
      - alert: LogOpsVeryHighMissingLevel
        expr: increase(logops_accepted_total[5m]) >= 200
          and ( increase(logops_missing_level_total[5m])
                / clamp_min(increase(logops_accepted_total[5m]), 1) ) > 0.50
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Very high share of missing levels"
          description: "Udział braków level > 50% przy ≥200 logach w 5m."

      # 9) Inflight stuck high
      - alert: LogOpsInflightStuckHigh
        expr: logops_inflight > 5
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Inflight gauge high"
          description: "logops_inflight > 5 przez ≥2m (przeciążenie lub zator)."

      # 10) Absent metrics from gateway
      - alert: LogOpsMetricsAbsent
        expr: absent(up{job="logops-gateway"})
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "No metrics scraped from gateway"
          description: "Prometheus nie widzi żadnych metryk z job='logops-gateway' przez ≥2m."

  - name: logops.slo
    interval: 15s
    rules:
      # % batchy < 500ms (30m window)
      - alert: LogOpsSLOUnder99
        expr: |
          (
            sum(rate(logops_batch_latency_seconds_bucket{le="0.5"}[30m]))
          /
            sum(rate(logops_batch_latency_seconds_count[30m]))
          ) < 0.99
        for: 30m
        labels:
          severity: warning
          service: logops
          team: platform
        annotations:
          summary: "SLO: <99% batchy <500ms (30m)"
          description: "Obecnie {{ $value | printf \"%.2f\" }} < 0.99; sprawdź przeciążenie/IO."

      # p95 latency > 0.5s (5m)
      - alert: LogOpsP95LatencyHigh
        expr: |
          histogram_quantile(
            0.95,
            sum by (le) (rate(logops_batch_latency_seconds_bucket[5m]))
          ) > 0.5
        for: 5m
        labels:
          severity: critical
          service: logops
          team: platform
        annotations:
          summary: "p95 batch latency > 500ms (≥5m)"
          description: "p95={{ $value | printf \"%.3f\" }}s; zweryfikuj load, CPU, disk, backpressure."
