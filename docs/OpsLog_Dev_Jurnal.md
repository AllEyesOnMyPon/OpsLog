# OpsLog Dev Journal

---

## Day 0 

---

### Struktura repo

**Cel:** *przygotowaÄ‡ pusty szkielet repozytorium pod projekt* **LogOps**.

**Kroki i Å›cieÅ¼ki:**

```powershell
PS C:\Users\kleme\Documents\Github\dev_playground> cd logops
PS C:\Users\kleme\Documents\Github\dev_playground\logops> git init
Initialized empty Git repository in C:/Users/kleme/Documents/Github/dev_playground/logops/.git/
```

â¡ï¸ ZainicjowaÅ‚em puste repozytorium Git w folderze `logops`.

```powershell
PS C:\Users\kleme\Documents\Github\dev_playground\logops> mkdir -p services/ingest-gateway
PS C:\Users\kleme\Documents\Github\dev_playground\logops> mkdir infra/docker
PS C:\Users\kleme\Documents\Github\dev_playground\logops> mkdir docs
PS C:\Users\kleme\Documents\Github\dev_playground\logops> mkdir tests/unit
```

â¡ï¸ UtworzyÅ‚em katalogi na serwisy, infrastrukturÄ™, dokumentacjÄ™ i testy.

```powershell
PS C:\Users\kleme\Documents\Github\dev_playground\logops> ni README.md
PS C:\Users\kleme\Documents\Github\dev_playground\logops> ni .gitignore
```

â¡ï¸ UtworzyÅ‚em puste pliki `README.md` i `.gitignore`.

```powershell
PS C:\Users\kleme\Documents\Github\dev_playground\logops> git add .
PS C:\Users\kleme\Documents\Github\dev_playground\logops> git commit -m "init: scaffold repo"
```

â¡ï¸ Pierwszy commit ze strukturÄ… repozytorium.

### Lokalne Å›rodowisko Pythona

**Cel**: *przygotowaÄ‡ izolowane Å›rodowisko .venv i zainstalowaÄ‡ paczki dla gatewayâ€™a*.

**Kroki i Å›cieÅ¼ki**:

```powershell
PS C:\Users\kleme\Documents\Github\dev_playground\logops> py -m venv .venv
```

â¡ï¸ UtworzyÅ‚em Å›rodowisko wirtualne .venv w folderze projektu.

```powershell
PS C:\Users\kleme\Documents\Github\dev_playground\logops> Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
PS C:\Users\kleme\Documents\Github\dev_playground\logops> .venv\Scripts\Activate.ps1
(.venv) PS C:\Users\kleme\Documents\Github\dev_playground\logops>
```

â¡ï¸ Tymczasowo zezwoliÅ‚em na uruchamianie skryptÃ³w PowerShell **tylko dla tej sesji**. DziÄ™ki temu nie zmieniam globalnych ustawieÅ„ systemu.

â¡ï¸ AktywowaÅ‚em Å›rodowisko `.venv` i od teraz wszystkie polecenia `pip`/`python` dziaÅ‚ajÄ… wewnÄ…trz tego projektu.

```powershell
(.venv) PS C:\Users\kleme\Documents\Github\dev_playground\logops> .\.venv\Scripts\python.exe -m pip install --upgrade pip
(.venv) PS C:\Users\kleme\Documents\Github\dev_playground\logops> .\.venv\Scripts\python.exe -m pip --version
pip 25.2 from ... (python 3.9)
```

â¡ï¸ ZaktualizowaÅ‚em pip wewnÄ…trz Å›rodowiska.

```powershell
(.venv) PS C:\Users\kleme\Documents\Github\dev_playground\logops> .\.venv\Scripts\python.exe -m pip install fastapi uvicorn pydantic[dotenv] requests
```

â¡ï¸ ZainstalowaÅ‚em paczki dla gatewayâ€™a:

- fastapi â€“ framework,
- uvicorn â€“ serwer,
- pydantic â€“ walidacja danych,
- requests â€“ klient HTTP.

```powershell
WARNING: pydantic 2.x does not provide the extra 'dotenv'
# Instalacja:
(.venv) PS C:\Users\kleme\Documents\Github\dev_playground\logops> .\.venv\Scripts\python.exe -m pip install python-dotenv

```
â¡ï¸ Wersja 2.x Pydantic nie obsÅ‚uguje juÅ¼ `[dotenv]`, wiÄ™c doinstalowaÅ‚em osobno python-dotenv.

```powershell
(.venv) PS C:\Users\kleme\Documents\Github\dev_playground\logops> .\.venv\Scripts\python.exe -m pip freeze > services/ingest-gateway/requirements.txt
```
â¡ï¸ ZapisaÅ‚em wszystkie zaleÅ¼noÅ›ci do `requirements.txt`, Å¼eby zawsze daÅ‚o siÄ™ odtworzyÄ‡ Å›rodowisko.

### FastAPI Ingest Gateway

**Cel**: *tworzenie pliku* `services/ingest_gateway/gateway.py` *a w nim poczÄ…tkowo tylko* `FastAPI` *z* `/healthz`.

```python
from fastapi import FastAPI

app = FastAPI()

@app.get("/healthz")
def healthz():
    return {"status": "ok"}
```

1. **Pierwszy run serwera:**

```lua
.venv\Scripts\python.exe -m uvicorn services.ingest_gateway.gateway:app --reload --port 8080
```
âœ… `/healthz` zwrÃ³ciÅ‚ `{ "status": "ok" }`.

2. **PrÃ³ba POST â†’ bÅ‚Ä…d walidacji**

PrÃ³ba wysÅ‚ania JSON:
```bash
irm -Method Post -Uri http://127.0.0.1:8080/v1/logs `
  -ContentType 'application/json' `
  -Body '{"msg":"hello"}'
```

âŒ BÅ‚Ä…d:

```json
{"detail":[{"type":"missing","loc":["query","payload"],"msg":"Field required"}]}
```
Przyczyna: endpoint w `gateway.py` miaÅ‚ argument `payload` jako query param, a nie body.

3. **Refactor endpointu na body**

```python
from fastapi import FastAPI, Request

app = FastAPI()

@app.post("/v1/logs")
async def ingest_logs(request: Request):
    payload = await request.json()
    return {"accepted": len(payload) if isinstance(payload, list) else 1}
```
4. **Testy `irm`**

- PojedyÅ„czy log:
```bash
irm -Method Post -Uri http://127.0.0.1:8080/v1/logs `
  -ContentType 'application/json' `
  -Body '{"msg":"hello"}'
```
âœ… OdpowiedÅº:
```powershell
accepted ts
-------- --
       1 2025-08-19T17:31:46.957050+00:00
```
- Lista logÃ³w
```bash
irm -Method Post -Uri http://127.0.0.1:8080/v1/logs `
  -ContentType 'application/json' `
  -Body '[{"msg":"a"},{"msg":"b"}]'
```
âœ… OdpowiedÅº:
```powershell
accepted ts
-------- --
       2 2025-08-19T17:31:53.936677+00:00
```
5. **PrÃ³by `curl.exe` â€” problemy**
- Manualny JSON
```powershell
curl.exe -s -X POST "http://127.0.0.1:8080/v1/logs" `
  -H "Content-Type: application/json" `
  --data-raw "{\"msg\":\"hello\"}"
```
âŒ Rezultat: `Internal Server Error`

Przyczyna: PowerShell + `curl.exe` Åºle parsujÄ… i mieszajÄ… stringi (escapowanie).

- Zmienna
```powershell
$one = "{""msg"":""hello""}"
curl.exe -s -X POST "http://127.0.0.1:8080/v1/logs" `
  -H "Content-Type: application/json" `
  --data-raw $one
```
âŒ Rezultat: `Internal Server Error`

Przyczyna: JSON przesyÅ‚any z niepoprawnym quotingiem (serwer wyrzuca `JSONDecodeError`).

- STDIN (nasza prÃ³ba z `@-`)
```powershell
@{ msg = "hello" } |
  ConvertTo-Json -Compress |
  curl.exe -s -X POST "http://127.0.0.1:8080/v1/logs" `
    -H "Content-Type: application/json" `
    --data-binary @-
```
âŒ W PowerShell â†’ `Unrecognized token '@-'`

W Bash/Linux by zadziaÅ‚aÅ‚o, ale w PowerShell jest parser error.

6. Decyzja â†’ uÅ¼ywamy irm

âœ”ï¸ `Invoke-RestMethod` (`irm`) jest natywny dla PowerShell, dziaÅ‚a **bez kombinacji z escapowaniem**.

âœ”ï¸ ObsÅ‚uguje JSON z **ConvertTo-Json**, wiÄ™c payload moÅ¼e byÄ‡ budowany dynamicznie:
```powershell
@{ msg = "hello" } | ConvertTo-Json -Compress |
  irm -Method Post -Uri http://127.0.0.1:8080/v1/logs `
    -ContentType 'application/json' `
    -Body $_
```
`curl.exe` zostaje tylko do:

cross-platform scriptÃ³w (Linux/Mac + Windows)

testÃ³w z pliku (``--data-binary "@file.json"``)

**Podsumowanie**
- **PoczÄ…tkowy bÅ‚Ä…d**: FastAPI traktowaÅ‚ payload jako query param â†’ naprawione przez request.json().

- `irm` **dziaÅ‚a od razu**: proste wysyÅ‚anie pojedynczego JSON i listy.

- `curl.exe` **w PowerShell = problemy**: escapowanie stringÃ³w i STDIN trudne do uÅ¼ycia.

- **Decyzja:**

    - w PowerShell â†’ irm (proste i natywne)

    - w cross-platform â†’ `curl --data-binary` z plikiem/STDIN

## Day 1

â¡ï¸**Cel**: Gateway: normalizacja + liczniki + poprawa logowania

**ÅšcieÅ¼ka robocza**:
`C:\Users\kleme\Documents\Github\dev_playground\logops`

**Zmiany w kodzie**:

`services\ingest_gateway\gateway.py` â€” endpoint `/v1/logs` czyta surowe body (`Request.json()`),

normalizacja pÃ³l do: `ts / level / msg`,

liczniki: `missing_ts` i `missing_level`,

logger zamiast `print()`.

**Start serwera (okno A)**:
```powershell
cd C:\Users\kleme\Documents\Github\dev_playground\logops
.\.venv\Scripts\python.exe -m uvicorn services.ingest_gateway.gateway:app --reload --reload-dir .\services\ingest_gateway --port 8080
```
**Testy (okno B)**:
```powershell
cd C:\Users\kleme\Documents\Github\dev_playground\logops

# health
irm http://127.0.0.1:8080/healthz

# batch minimalny (PS-native JSON)
$batch = @(@{ msg = "a" }, @{ msg = "b" }) | ConvertTo-Json -Compress
irm -Method Post -Uri http://127.0.0.1:8080/v1/logs -ContentType 'application/json' -Body $batch
```
**Oczekiwane**:

- OdpowiedÅº API (okno B): `{"accepted":2,"ts":"...","missing_ts":2,"missing_level":2}`

- Log serwera (okno A): `INFO gateway: [ingest] accepted=2 missing_ts=2 missing_level=2`

**Notatka**:
W PowerShell uÅ¼ywamy `Invoke-RestMethod (irm)` â€” stabilnie przekazuje JSON; `curl.exe` Å‚atwo â€psujeâ€ cudzysÅ‚owy.

â¡ï¸**Cel**:Emiter â€server-styleâ€ (`emit_json`)

**Plik**: `emitters\emitter_json\emit_json.py`

**Uruchomienie (z katalogu projektu):**
```powershell
cd C:\Users\kleme\Documents\Github\dev_playground\logops
.\.venv\Scripts\python.exe .\emitters\emitter_json\emit_json.py -n 10 --partial-ratio 0.3
```
**Oczekiwane (w oknie emitera):**
```powershell
status: 200
body: {"accepted":10,"ts":"...","missing_ts":X,"missing_level":Y}
```
**Dlaczego tak:**
Ten emiter ma generowaÄ‡ â€serwerowyâ€ JSON z polami typu `timestamp/level/message/....` CzÄ™Å›Ä‡ rekordÃ³w z brakami (`--partial-ratio`) testuje normalizacjÄ™ i liczniki.

â¡ï¸**Cel**: Emiter â€minimalâ€ (`emit_minimal.py` *:tylko msg*)

**Plik**: `emitters\emitter_minimal\emit_minimal.py`

**Uruchomienie (z katalogu projektu):**
```powershell
cd C:\Users\kleme\Documents\Github\dev_playground\logops
.\.venv\Scripts\python.exe .\emitters\emitter_minimal\emit_minimal.py -n 10
.\.venv\Scripts\python.exe .\emitters\emitter_minimal\emit_minimal.py -n 25
```
**Oczekiwane (emiter)**:
```powershell
status: 200
body: {"accepted":25,"ts":"...","missing_ts":25,"missing_level":25}
```

**Oczekiwane (log serwera)**:
```powershell
INFO gateway: [ingest] accepted=25 missing_ts=25 missing_level=25
```

**Uwagi:**
Ten emiter Å›wiadomie nie wysyÅ‚a `ts` ani `level`, Å¼eby zobaczyÄ‡, Å¼e gateway uzupeÅ‚nia `ts` i mapuje `level` domyÅ›lnie.

â¡ï¸**Cel**: PorzÄ…dki: usuniÄ™cie starego folderu i wypchniÄ™cie zmian

**UsuniÄ™cie starego katalogu (myÅ›lnik â†’ podkreÅ›lnik):**
```powershell
cd C:\Users\kleme\Documents\Github\dev_playground\logops
Remove-Item -Recurse -Force .\services\ingest-gateway
```
**Commit + push:**
```powershell
git status
git add .
git commit -m "cleanup: remove old ingest-gateway, update ingest_gateway, add emitter_json, add emitter_minimal"
git push origin main
```
**Dlaczego tak:**
Python importuje pakiety z podkreÅ›lnikami -(`ingest_gateway`). Stary katalog z myÅ›lnikiem potrafiÅ‚ myliÄ‡ reloader.

**âœ… Stan na koniec**

- Gateway: `/healthz`, `/v1/logs` (normalizacja + liczniki + logger).

- Emitery: `emitter_json` (server-style), `emitter_minimal` (only msg).

- Repo: posprzÄ…tane (`ingest_gateway` jako jedyny katalog usÅ‚ugi), zmiany wypchniÄ™te na main.

â¡ï¸**Cel**: RÃ³Å¼norodne emitery + rozszerzenia gateway

PokryÄ‡ **typowe style** logÃ³w spotykane w projektach:

- **Ustrukturyzowany JSON** `emit_json.py` (aplikacje/serwisy) âœ…,

- **Tylko msg** `emit_minimal.py` (skrypt, log biblioteki) âœ…,

- **Linie tekstowe** `emit_syslog.py` (syslog) âŒ,

- **CSV** `emit_csv.py` (eksporty/ETL) âŒ,

- **â€Szumâ€** `emit_noise.py` (chaotyczne i niejednorodne rekordy spotykane w integracjach) âŒ.

DziÄ™ki temu gateway musi umieÄ‡ **rozpoznaÄ‡ format, wyciÄ…gnÄ…Ä‡ kluczowe pola i znormalizowaÄ‡** je do wspÃ³lnego schematu `ts/level/msg`, raportujÄ…c jednoczeÅ›nie braki (`missing_ts`, `missing_level`).

**Zmiany w gateway (przeglÄ…d)**

- Dodano obsÅ‚ugÄ™ formatÃ³w wejÅ›ciowych:

    - `application/json` â€” obiekt lub lista obiektÃ³w,

    - `text/plain` â€” wielolinijkowe logi w stylu syslog (parser linii),

    - `text/csv` â€” CSV z nagÅ‚Ã³wkiem (np. `ts,level,msg`).

- Utrzymano normalizacjÄ™ do `ts` / `level` / `msg` + liczniki brakÃ³w.

- Ulepszono logowanie (logger zamiast `print`).

- Wersjonowanie w `/healthz`:

    - `v5-text-support` (po dodaniu `text/plain`),

    - `v6-csv-support` (po dodaniu `text/csv`).

### Emitery (dlaczego te typy + jak testowaÅ‚em)

1. **`emitter_json` â€” â€server-styleâ€ JSON**

**Dlaczego**: To najczÄ™stszy format z aplikacji (API, mikroserwisy).

**Plik**: `emitters\emitter_json\emit_json.py`

**Test**: Robiony wczeÅ›niej w dziennikuâ¬†ï¸

2. **`emitter_minimal` â€” tylko msg**

**Dlaczego**: Minimalny przypadek z reala (np. prosty skrypt lub log z biblioteki), testuje uzupeÅ‚nianie brakÃ³w.

**Plik**: `emitters\emitter_minimal\emit_minimal.py`

**Test**: Robiony wczeÅ›niej w dziennikuâ¬†ï¸

3. **`emitter_syslog` â€” linie tekstowe (legacy/syslog-like)**

**Dlaczego**: Wiele starszych systemÃ³w wypisuje logi jako linie tekstowe (`syslog`). To wymusza parser linii po stronie gateway.

**Plik**: `emitters\emitter_syslog\emit_syslog.py`

Wymagane w gateway: wsparcie `text/plain` + regex parser.

**Test**:
```powershell
.\.venv\Scripts\python.exe .\emitters\emitter_syslog\emit_syslog.py -n 15 --partial-ratio 0.4
```
**Oczekiwane**: `200 OK`, sensowne liczniki brakÃ³w (czÄ™Å›Ä‡ linii celowo â€ubogaâ€).

4) **`emitter_csv` â€” CSV (`ts`,`level`,`msg`)**

**Dlaczego**: CSV bywa formatem wymiany (eksporty, ETL). Åatwy do manualnego generowania, ale wymaga parsera.

**Plik**: `emitters\emitter_csv\emit_csv.py`

**Wymagane w gateway**: wsparcie `text/csv` + `csv.DictReader`.

**Test**:
```powershell
.\.venv\Scripts\python.exe .\emitters\emitter_csv\emit_csv.py -n 12 --partial-ratio 0.4
```
**Oczekiwane**: `200 OK`, liczniki zaleÅ¼ne od pustych kolumn.

5) **`emitter_noise` â€” chaos/edge cases**

**Dlaczego**: Symulacja â€prawdziwego Å¼yciaâ€: aliasy pÃ³l (`message/msg/log`), dziwne typy (`bool/int` zamiast `str`), zagnieÅ¼dÅ¼enia, braki.

**Plik**: `emitters\emitter_noise\emit_noise.py`

**Test**: 
```powershell
.\.venv\Scripts\python.exe .\emitters\emitter_noise\emit_noise.py --chaos 0.5 -n 20
```
**Oczekiwane**: `200 OK`, zwykle wyÅ¼sze `missing_ts`/`missing_level`; gateway nadal zwraca spÃ³jny rezultat.

**Jak testowaÅ‚em (wzorce)**

- **Zawsze 2 okna:**

    - **A: serwer** (`uvicorn ... --reload`) â†’ logi gateway (`[ingest] accepted=... missing_ts=...`),

    - **B: emiter** â†’ `status: 200` i `body: {...}`.

- **PowerShell**: testy JSON robiÅ‚em `Invoke-RestMethod (irm)`, bo unika problemÃ³w z cudzysÅ‚owami; dla `text/plain` i `text/csv` ustawiaÅ‚em odpowiedni `Content-Type`.

- `/healthz`: kontrola wersji gateway po kaÅ¼dym patchu (np. `v5-text-support`, `v6-csv-support`).

**âœ… Stan na teraz:**

- **Gateway**: `/healthz`, `/v1/logs` z obsÅ‚ugÄ… `application/json`, `text/plain`, `text/csv`; normalizacja `ts/level/msg` + liczniki brakÃ³w; logger.

- **Emitery**:

    - `emitter_json` (server-style),

    - `emitter_minimal` (only `msg`),

    - `emitter_syslog` (linie tekstowe),

    - `emitter_csv` (CSV z nagÅ‚Ã³wkiem),

    - `emitter_noise` (chaotyczne rekordy).

- **Repo**: aktualne, posprzÄ…tane, wszystkie testy przeszÅ‚y lokalnie.

### **ğŸ“Œ WdroÅ¼enie szyfrowania danych wraÅ¼liwych (PII) â€“ `wersja v7-pii-encryption`**

1. **Cel**

Dodanie maskowania oraz szyfrowania danych wraÅ¼liwych (PII), takich jak adresy e-mail i adresy IP, w systemie LogOps.
Maskowanie sÅ‚uÅ¼y do logÃ³w/analityki, natomiast szyfrowanie zapewnia bezpieczne przechowywanie surowych danych.

2. **Implementacja**

Dodano obsÅ‚ugÄ™ konfiguracji w `.env`:

```ini
LOGOPS_SECRET_KEY=...         # klucz Fernet
LOGOPS_ENCRYPT_PII=true       # wÅ‚Ä…czenie szyfrowania
LOGOPS_ENCRYPT_FIELDS=user_email,client_ip
LOGOPS_DEBUG_SAMPLE=true
LOGOPS_DEBUG_SAMPLE_SIZE=3
```
- Zaimplementowano:

    - **Maskowanie** emaili (`u***@example.com`) i IP (`83.11.x.x`).

    - **Szyfrowanie Fernet** dla pÃ³l wskazanych w `LOGOPS_ENCRYPT_FIELDS` oraz caÅ‚ej wiadomoÅ›ci (`msg`).

    - Dodanie zaszyfrowanych wersji pÃ³l z sufiksem `_enc` (np. `user_email_enc`).

- Rozszerzono normalizacjÄ™ rekordÃ³w tak, aby zawsze zwracaÅ‚a:

    - `msg` â€“ zamaskowany,

    - `msg_enc` â€“ zaszyfrowany,

    - `user_email` / `client_ip` â€“ zamaskowane,

    - `user_email_enc` / `client_ip_enc` â€“ zaszyfrowane.

3. **Napotkany problem: `.env` z BOM**

Podczas testÃ³w API pojawiaÅ‚ siÄ™ komunikat:

```powershell
PII encryption enabled but no LOGOPS_SECRET_KEY set; disabling encryption.
```
Mimo Å¼e `.env` zawieraÅ‚ prawidÅ‚owy wpis `LOGOPS_SECRET_KEY=...`.

Po diagnostyce okazaÅ‚o siÄ™, Å¼e plik `.env` zostaÅ‚ zapisany z **UTF-8 BOM**:

4. **Diagnostyka**

GÅ‚Ã³wny katalog `LogOps`:
```powershell
Get-Content .\.env -Encoding Byte -TotalCount 16
```
â¡ï¸ Pokazuje pierwsze bajty pliku (tu 16 sztuk), wyÅ›wietla liczby dziesiÄ™tne, np. `239 187 191 76 79 71 ...`.

```powershell
Get-Content .\.env -Encoding Byte -TotalCount 16
```
â¡ï¸ Pokazuje linie â€jak leciâ€ (Å¼eby wykluczyÄ‡ literÃ³wki/spacje)

**Jak rozrÃ³Å¼niÄ‡ najczÄ™stsze UTF-y po bajtach (BOM)**

| Kodowanie         | Sygnatura na poczÄ…tku pliku (BOM) | Bajty dziesiÄ™tne   | Jak to rozpoznaÄ‡ w praktyce |
|-------------------|-----------------------------------|--------------------|-----------------------------|
| **UTF-8 bez BOM** | brak                              | np. `76 79 71`     | Najlepsze dla `.env`. Brak dodatkowych bajtÃ³w z przodu. |
| **UTF-8 z BOM**   | `EF BB BF`                        | `239 187 191`      | `python-dotenv` moÅ¼e nie widzieÄ‡ pierwszego klucza (BOM dokleja siÄ™ do nazwy). |
| **UTF-16 LE**     | `FF FE`                           | `255 254`          | KaÅ¼da litera ma â€0â€ obok: np. `76 0 79 0 71 0...`. |
| **UTF-16 BE**     | `FE FF`                           | `254 255`          | OdwrotnoÅ›Ä‡ LE: `0 76 0 79 0 71...`. |
| **UTF-32 LE**     | `FF FE 00 00`                     | `255 254 0 0`      | Rzadka w takich plikach. |
| **UTF-32 BE**     | `00 00 FE FF`                     | `0 0 254 255`      | Rzadka. |

W tym przypadku byÅ‚o `239 187 191` â†’ `UTF-8 z BOM`. Dlatego `python-dotenv` nie widziaÅ‚ `LOGOPS_SECRET_KEY` (nazwÄ™ czytaÅ‚ jako `\ufeffLOGOPS_SECRET_KEY`).

**Konwersja UTF-8 z BOM -> UTF-8 bez**

- Przez .NET
```powershell
$body = Get-Content .\.env -Raw
$utf8NoBom = New-Object System.Text.UTF8Encoding($false)  # false = bez BOM
[System.IO.File]::WriteAllText(".\.env", $body, $utf8NoBom)
```
W tym przypadku plik byl zablokowany wiÄ™c `WriteAllText` pod nazwa `.env.novbom`, `Remove` `.env` i `Rename` `.envnobom` na `.env`
```powershell
[System.IO.File]::WriteAllText(".\.env.nobom", $body, $utf8NoBom)
Remove-Item .\.env
Rename-Item .\.env.nobom .env
```
- Testy po konwersji:

ğŸ” Sprawdzam czy BOM zniknÄ…Å‚:

```powershell
Get-Content .\.env -Encoding Byte -TotalCount 3   # powinno NIE byÄ‡ 239 187 191
```
ğŸ” Sprawdzam przez Gateway:

```powershell
.\.venv\Scripts\python.exe -m uvicorn services.ingest_gateway.gateway:app --reload --port 8080
irm http://127.0.0.1:8080/healthz
# oczekuj: pii_encryption : True
```
- **Dlaczego to miaÅ‚o znaczenie dla `.env`**

    - BOM (np. `EF BB BF`) â€przykleja siÄ™â€ do **pierwszego klucza** w pliku.

    - Biblioteka `python-dotenv` widzi wtedy zmiennÄ… o nazwie `\ufeffLOGOPS_SECRET_KEY` zamiast `LOGOPS_SECRET_KEY`.

    - Efekt: kod myÅ›li, Å¼e **sekret nie istnieje** â†’ szyfrowanie wyÅ‚Ä…czone.

**â„¹ï¸Ciekawostka**

Po `load_dotenv(...)` moÅ¼na dodaÄ‡ krÃ³tki log:
```python
import os
print("DEBUG env:", os.getenv("LOGOPS_SECRET_KEY"), os.getenv("LOGOPS_ENCRYPT_PII"))
```
JeÅ›li `LOGOPS_SECRET_KEY` jest `None`, a wiesz, Å¼e jest w pliku, to pierwsze co sprawdzasz â€” **BOM**.

5. **Testy koÅ„cowe**:

**Health check**
```powershell
irm http://127.0.0.1:8080/healthz
```
âœ… Wynik:
```powershell
status version           pii_encryption
------ -------           --------------
ok     v7-pii-encryption           True
```

**Test danych wejÅ›ciowych**
```powershell
$batch = @(
  @{ message = "login ok user=user1@example.com from 83.11.22.33"; level = "info"; user_email="user1@example.com"; client_ip="83.11.22.33" },
  @{ msg = "fatal error for user2@example.com from 10.1.2.3" }
) | ConvertTo-Json -Compress

$res = irm -Method Post -Uri http://127.0.0.1:8080/v1/logs -ContentType 'application/json' -Body $batch
$res
```
âœ… Wynik:

- `msg` zamaskowany (`u***@example.com`, `83.11.x.x`).

- `msg_enc`, `user_email_enc`, `client_ip_enc` â€“ zaszyfrowane wartoÅ›ci.

- `user_email`, `client_ip` â€“ zamaskowane do analityki.

- Brak bÅ‚Ä™dÃ³w, `accepted=2`.


**6. Podsumowanie**


- **Problem**: `.env` z BOM uniemoÅ¼liwiaÅ‚ odczyt LOGOPS_SECRET_KEY.

- **RozwiÄ…zanie**: zapis pliku `.env` w czystym UTF-8 bez BOM.

- **Efekt**: szyfrowanie PII aktywne, testy potwierdziÅ‚y maskowanie + szyfrowanie.

- **Dalsze kroki**:

    - Rotacja klucza `LOGOPS_SECRET_KEY` wg polityki bezpieczeÅ„stwa.

    - WyÅ‚Ä…czenie `LOGOPS_DEBUG_SAMPLE` w produkcji.

    - Opcjonalny endpoint `/debug/decrypt` do lokalnego testu odszyfrowania.

## Day 2

### Housekeeping (retencja/archiwizacja)

**Cel**: DodaÄ‡ lekki moduÅ‚ housekeeping, ktÃ³ry automatycznie sprzÄ…ta dzienne pliki NDJSON z katalogu `data/ingest` zgodnie z retencjÄ…. Opcjonalnie archiwizuje stare pliki do ZIP.

**1. Skrypt narzÄ™dziowy**

Dodano `tools/housekeeping.py`:

- czyta konfiguracjÄ™ z `.env` (`LOGOPS_RETENTION_DAYS`, `LOGOPS_ARCHIVE_MODE`, `LOGOPS_SINK_DIR`),

- dla plikÃ³w `YYYYMMDD.ndjson` porÃ³wnuje datÄ™ z retencjÄ…,

- tryb `delete`: usuwa pliki starsze niÅ¼ N dni,

- tryb `zip`: pakuje plik do `data/archive/YYYYMMDD`.zip, potem usuwa ÅºrÃ³dÅ‚o,

- eksportuje `run_once()` â€“ â€mostekâ€ do wywoÅ‚ania z gatewaya.

**2. Mostek w gateway (autorun przez lifespan)**

W `services/ingest_gateway/gateway.py`:

- uruchamianie housekeeping **raz przy starcie** (`LOGOPS_HOUSEKEEP_AUTORUN=true`),

- (opcjonalnie) pÄ™tla **okresowa** co N sekund `(LOGOPS_HOUSEKEEP_INTERVAL_SEC>0`),

- logi w konsoli, np.:

    - `[housekeep] run_once at startup done`

    - `[housekeep] deleted 20250818.ndjson`

    - [`housekeep] archived 20250818.ndjson` -> `20250818.zip`

**3. Konfiguracja `.env` (fragment)**:
```ini
# File sink
LOGOPS_SINK_FILE=true
LOGOPS_SINK_DIR=./data/ingest

# Housekeeping (lifecycle)
LOGOPS_RETENTION_DAYS=2
LOGOPS_ARCHIVE_MODE=delete   # delete | zip

# Autorun (gateway lifespan)
LOGOPS_HOUSEKEEP_AUTORUN=true
LOGOPS_HOUSEKEEP_INTERVAL_SEC=0   # 0 = tylko na starcie; np. 3600 = co godzinÄ™
```
**Jak to dziaÅ‚a w praktyce**

1. **Zapis dobowy**: gateway zapisuje znormalizowane logi do `data/ingest/YYYYMMDD.ndjson`.

2. **SprzÄ…tanie**: przy starcie gatewaya (i ewentualnie cyklicznie) uruchamia siÄ™ housekeeping:

    - identyfikuje pliki â€przeterminowaneâ€ wzglÄ™dem `LOGOPS_RETENTION_DAYS`,

    - **usuwa** (delete) lub **archiwizuje** (zip),

    - loguje akcje w konsoli.

## Day 3

### ObserwowalnoÅ›Ä‡ w Å›rodowisku Docker 

**Cel:** Zbudowanie podstawowego stacku monitoringowo-logowego w oparciu o cztery komponenty:

- Promtail â€“ agent zbierajÄ…cy logi NDJSON z katalogu projektu, parsujÄ…cy je i wysyÅ‚ajÄ…cy do Loki,

- Loki â€“ magazyn logÃ³w zoptymalizowany pod query w Grafanie,

- Prometheus â€“ zbiera metryki z logops gatewaya (liczniki accepted/missing itp.) oraz obsÅ‚uguje reguÅ‚y alertowe,

- Grafana â€“ dashboardy dla logÃ³w i metryk.

- Zmiana struktury katalogÃ³w. WczeÅ›niej wszystkie configi byÅ‚y w `infra/docker/`. Wprowadzilem bardziej uporzÄ…dkowanÄ… strukturÄ™:

```markdown
infra/
â””â”€â”€ docker/
    â”œâ”€â”€ docker-compose.yml
    â”œâ”€â”€ prometheus/
    â”‚   â”œâ”€â”€ prometheus.yml
    â”‚   â””â”€â”€ alert_rules.yml
    â”œâ”€â”€ loki/
    â”‚   â””â”€â”€ loki-config.yml
    â””â”€â”€ promtail/
        â””â”€â”€ promtail-config.yml
```
DziÄ™ki temu kaÅ¼dy serwis ma swÃ³j wÅ‚asny katalog, a `docker-compose.yml` jedynie montuje pliki konfiguracyjne.

**Kluczowe implementacje:**

**1. Promtail**

- ustawienie `positions.filename: /var/lib/promtail/positions.yaml` i podmontowaliÅ›my wolumen `promtail-data` â†’ offsety sÄ… utrwalane miÄ™dzy restartami, wiÄ™c nie ma re-ingestu starych linii,

- dodanie `start_position`: end â†’ agent zaczyna czytaÄ‡ od koÅ„ca pliku,

- `pipeline_stages` parsuje NDJSON, mapuje `ts`, `level`, `msg`, `emitter`, a resztÄ™ wysyÅ‚a jako payload.

**2. Loki**

- przeniesiony config do `infra/docker/loki/`,

- problemy z bÅ‚Ä™dnym polem `path` w configu â†’ poprawione, serwis startuje czysto,

- dane trzymane w wolumenie `loki-data`.

**3. Prometheus**

skonfigurowany do scrapowania `logops_gateway` i `self-metrics` innych serwisÃ³w,

- doÅ‚Ä…czony plik `alert_rules.yml` (pusty),

umoÅ¼liwione **reloady** configu via `irm -Method Post http://localhost:9090/-/reload`.

**4. Grafana**

- postawione podstawowe dashboardy:

  - **Overview (Prometheus)** â€“ statystyki accepted/missing, inflight,

  - **Trends (Loki)** â€“ count_over_time wg levela,

  - **Emitters** â€“ rozbicie po polu emitter,

  - **Raw logs / Live tail** â€“ podglÄ…d bieÅ¼Ä…cych logÃ³w.

### ObserwowalnoÅ›Ä‡ - problemy i fixy

- **Promtail nie startowaÅ‚ â€“ pomyÅ‚ka: `promtail-config.yaml` vs `.yml`.**

  RozwiÄ…zanie: usuniÄ™cie duplikatu, spÃ³jne `.yml`.

- **Loki wyrzucaÅ‚ bÅ‚Ä™dy `failed to load chunk â€¦ no such file` przy starych danych.**
  
  RozwiÄ…zanie: czyszczenie wolumenu i ponowny start.

- **Brak Å›wieÅ¼ych logÃ³w w Grafanie â€“ rÃ³Å¼nica czasu (PL vs UTC).**
  
  RozwiÄ…zanie: timestampy w NDJSON sÄ… w UTC, Grafana teÅ¼ â†’ problem leÅ¼aÅ‚ w offsetach, naprawione po prawidÅ‚owym ustawieniu `positions` i s`tart_position`.

- **â€No volume availableâ€ w panelach â€“ Promtail nie miaÅ‚ wolumenu na offsety.**

  DodaliÅ›my wolumen `promtail-data:/var/lib/promtail`.

**Efekt**
- End-to-end pipeline dziaÅ‚a: logi NDJSON â†’ Promtail â†’ Loki â†’ Grafana.

- Prometheus zbiera metryki i rejestruje alerty.

- Dashboardy w Grafanie pokazujÄ… juÅ¼ dane live (Overview + Trends + Raw logs).

### Alerty Prometheus `alert_rules.yml`

**Cel:** Automatyczne wykrywanie anomalii w strumieniu logÃ³w.

**1. Struktura plikÃ³w**

- Alerty umieszczone w:
```bash
infra/docker/prometheus/alert_rules.yml
```
- Dodanie sekcji do `prometheus.yml`:
```bash
rule_files:
  - /etc/prometheus/alert_rules.yml
```
- Reload konfiguracji:
```powershell
irm -Method Post http://localhost:9090/-/reload
```
**2. Zainicjowane reguÅ‚y:**

**LogOpsGatewayDown**


  - Expr: `up{job="logops_gateway"} == 0`

  - For: **1m**

  - Severity: **critical**

ğŸ‘‰ Wykrywa, Å¼e gateway w ogÃ³le nie odpowiada na scrape.

âš¡ Parametr `for: 1m` chroni przed chwilowymi timeoutami.


**LogOpsNoIngest5m**


- Expr: `increase(logops_accepted_total[5m]) <= 0`

- For: **2m**

- Severity: **warning**

ğŸ‘‰ Alarmuje, jeÅ›li w oknie **5 minut** nie ma ani jednego przyjÄ™tego logu.

âš¡ Praktyczne do wykrycia caÅ‚kowitej przerwy w **ingest**.

**LogOpsLowIngest**


- Expr: `rate(logops_accepted_total[5m]) < 0.2`

- For: **5m**

- Severity: **info**

ğŸ‘‰ Wskazuje, Å¼e pipeline â€tli siÄ™â€ â€“ Å›rednio **<0.2 loga/s**.

âš¡ Informacyjny â€“ nie jest to awaria, ale sygnaÅ‚ podejrzanie niskiego ruchu.

**LogOpsHighIngestBurst**


- Expr: `rate(logops_accepted_total[1m]) > 20`

- For: **1m**

- Severity: **warning**

ğŸ‘‰ Wykrywa nagÅ‚e wzrosty ruchu (**â‰¥20 logÃ³w/s**).

âš¡ MoÅ¼e sygnalizowaÄ‡ sztorm bÅ‚Ä™dÃ³w, pÄ™tlÄ™ w aplikacji, albo **flood/DDoS**.

**LogOpsHighMissingTS**


- Expr: przy **â‰¥100 logach w 5m**, odsetek brakujÄ…cych **TS > 20%**

- For: **2m**

- Severity: **warning**

ğŸ‘‰ Wykrywa, Å¼e sporo logÃ³w nie ma pola `ts`.

âš¡ Dolny prÃ³g (**20%**) daje wczesne ostrzeÅ¼enie, ale wymaga teÅ¼ min. **100 logÃ³w** (Å¼eby uniknÄ…Ä‡ faÅ‚szywych alarmÃ³w przy maÅ‚ej prÃ³bce).

**LogOpsVeryHighMissingTS**

- Expr: przy **â‰¥200** logach w 5m, odsetek brakÃ³w TS > **50%**

- For: **2m**

- Severity: **critical**

ğŸ‘‰ Eskalacja alertu z punktu `LogOpsHighMissingTS`.

âš¡ Wysoki prÃ³g (**50%**) i wiÄ™ksza liczba logÃ³w (**200**) â†’ **alarm krytyczny**, oznacza masowe problemy z pipeline.

**LogOpsHighMissingLevel**


- Expr: analogiczne do (`LogOpsHighMissingTS`), ale dla pola level.

- For: **2m**

- Severity: **warning**

ğŸ‘‰ Ostrzega, gdy **â‰¥20%** logÃ³w nie ma poziomu (**INFO/ERROR/WARN/DEBUG**).

**LogOpsVeryHighMissingLevel**


Expr: analogiczne do `LogOpsVeryHighMissingTS`, ale dla pola `level`.

For: **2m**

Severity: **critical**

ğŸ‘‰ Krytyczny wariant dla brakÃ³w pola `level`.

**LogOpsInflightStuckHigh**


Expr: `logops_inflight > 5`

For: **2m**

Severity: **warning**

ğŸ‘‰ Monitoruje **gauge â€in-flightâ€** (np. liczba logÃ³w w kolejce).

âš¡ JeÅ›li **>5** przez **â‰¥2** minuty â†’ backpressure, przetwarzanie siÄ™ zapycha.

**LogOpsMetricsAbsent**


Expr: `absent(up{job="logops_gateway"})`

For: **2m**

Severity: **critical**

ğŸ‘‰ **Fallback** â€“ jeÅ›li Prometheus caÅ‚kowicie przestaje widzieÄ‡ metryki z gatewaya.

âš¡ Rozszerza alert nr 1 (nie tylko â€0â€, ale brak danych w ogÃ³le).

### **Podsumowanie**

- Mamy pokrycie **dostÄ™pnoÅ›ci** (GatewayDown, MetricsAbsent).

- Mamy pokrycie **wolumenu ruchu** (NoIngest, LowIngest, HighIngestBurst).

- Mamy kontrolÄ™ **jakoÅ›ci logÃ³w** (MissingTS, MissingLevel â€“ wariant warning i critical).

- Mamy kontrolÄ™ **kolejki** (Inflight).

To daje nam **peÅ‚ne minimum observability**: wykryjemy brak ruchu, anomalie ruchu, bÅ‚Ä™dy w danych i problemy systemowe.

### Rozdzielenie requirements na produkcyjne i developerskie

**Tworzenie dwÃ³ch zestawÃ³w plikÃ³w wymagaÅ„:**

- `services/ingest_gateway/requirements.txt` â€“ pakiety potrzebne do uruchomienia gatewayâ€™a (produkcja).

  Zawiera m.in.:

  - `fastapi`, `uvicorn` â†’ serwer API,

  - `python-dotenv` â†’ konfiguracja Å›rodowiska,

  - `cryptography` â†’ obsÅ‚uga szyfrowania,

  - `prometheus-client` â†’ eksport metryk,

  - `requests` â†’ komunikacja HTTP.


- `requirements-dev.txt` (root repo) â€“ pakiety przydatne do developmentu i testÃ³w.

  Zawiera m.in.:

  - `black`, `ruff` â†’ formatowanie i linting,

  - `mypy` â†’ typowanie,

  - `pytest`, `pytest-asyncio` â†’ testy,

  - `httpx` â†’ testy API.

**Cel:** 
- OddzieliÄ‡ to, co **niezbÄ™dne do dziaÅ‚ania** usÅ‚ugi, od narzÄ™dzi developerskich.

- DziÄ™ki temu kontenery produkcyjne bÄ™dÄ… lÅ¼ejsze i prostsze w utrzymaniu, a jednoczeÅ›nie mamy peÅ‚ne wsparcie narzÄ™dzi w Å›rodowisku developerskim.

**Efekt**:

- **Czystszy podziaÅ‚ obowiÄ…zkÃ³w:** gateway nie ciÄ…gnie za sobÄ… zbÄ™dnych paczek.

- **Lepsza kontrola zaleÅ¼noÅ›ci:** Å‚atwo sprawdziÄ‡, co jest â€coreâ€, a co jest tylko â€dev toolingâ€.

Przygotowane do automatyzacji buildÃ³w (np. Dockerfile moÅ¼e uÅ¼ywaÄ‡ tylko `requirements.txt` z katalogu usÅ‚ugi).

## Day 4-5 

2025/08/23-24 â€“ Dokumentacja i Structurizr

UporzÄ…dkowaÅ‚em strukturÄ™ dokumentacji w projekcie **LogOps**.  
Zasada jest prosta: gÅ‚Ã³wny `README.md` w root to **mapa projektu** i szybki start, a wszystkie szczegÃ³Å‚y sÄ… rozbite na osobne pliki w `docs/`.  

- `overview.md` â†’ przeglÄ…d projektu, co jest in scope / out of scope  
- `quickstart.md` â†’ jak uruchomiÄ‡ Å›rodowisko krok po kroku  
- `infra.md`, `observability.md` â†’ szczegÃ³Å‚y Dockera, Prometheus, Grafana, Loki, Promtail  
- `services/` â†’ opis Gatewaya i emiterÃ³w (kaÅ¼dy emiter ma wÅ‚asny README)  
- `tools/housekeeping.md` â†’ osobny opis skryptu czyszczÄ…cego archiwalne NDJSON  
- `architecture.md` â†’ diagramy C4 (C1, C2, C3)  

DziÄ™ki temu unikam Å›ciany tekstu â€“ kaÅ¼dy moduÅ‚ ma swoje miejsce i moÅ¼na Å‚atwo znaleÅºÄ‡ potrzebne info.

Dodatkowo uruchomiÅ‚em **Structurizr Lite** w kontenerze Dockera.  
Za jego pomocÄ… zdefiniowaÅ‚em model w DSL (`workspace.dsl`) i wyeksportowaÅ‚em diagramy C1â€“C3 do PNG.  
Teraz w `architecture.md` sÄ… podlinkowane gotowe obrazki (`c1.png`, `c2.png`, `c3.png`), wiÄ™c caÅ‚oÅ›Ä‡ jest czytelna rÃ³wnieÅ¼ w repo na GitHubie bez uruchamiania Structurizr.

Wnioski: **docs muszÄ… Å¼yÄ‡ rÃ³wnolegle z projektem nie jako uzupeÅ‚nienie bo Å‚atwo sie zgubiÄ‡ w miarÄ™ skalowania.**





